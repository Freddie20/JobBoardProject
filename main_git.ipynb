{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Initialize WebDriver with ChromeDriver\n",
    "options = Options()\n",
    "options.headless = True  # Run in headless mode\n",
    "driver_path = \"/Users/......\"  # Update the path to your Chromedriver\n",
    "service = Service(driver_path)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "def scrape_renaissance_jobs(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Let the page load\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Find all job listing items\n",
    "    jobs = soup.find_all('li', class_='opening-job job column wide-1of2 medium-1of2')\n",
    "    \n",
    "    job_data = []\n",
    "    \n",
    "    if not jobs:\n",
    "        print(f\"No job listings found on {url}.\")\n",
    "        return []\n",
    "    \n",
    "    for job in jobs:\n",
    "        title = job.find('h4', class_='details-title job-title link--block-target').text.strip()\n",
    "        link = job.find('a', class_='link--block details')['href'].strip()\n",
    "        \n",
    "        # Collect job data\n",
    "        job_data.append({\n",
    "            \"title\": title,\n",
    "            \"link\": link,\n",
    "        })\n",
    "    \n",
    "    return job_data\n",
    "\n",
    "# Test the scraper\n",
    "url = \"https://careers.....\" #Add URl for testing\n",
    "jobs = scrape_renaissance_jobs(url)\n",
    "\n",
    "if jobs:\n",
    "    for job in jobs:\n",
    "        print(job)\n",
    "else:\n",
    "    print(\"No jobs found.\")\n",
    "\n",
    "# Quit the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Initialize WebDriver with ChromeDriver\n",
    "options = Options()\n",
    "options.headless = True  # Run in headless mode\n",
    "driver_path = \"/Users/.......\"  # Update the path to your Chromedriver\n",
    "service = Service(driver_path)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "def scrape_company_jobs(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Let the page load fully\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Find all job listing items\n",
    "    jobs = soup.find_all('li', class_='whr-item')\n",
    "    \n",
    "    job_data = []\n",
    "    \n",
    "    if not jobs:\n",
    "        print(f\"No job listings found on {url}.\")\n",
    "        return []\n",
    "    \n",
    "    for job in jobs:\n",
    "        # Directly search for the h3 tag containing the a tag\n",
    "        h3_tag = job.find('h3', class_='whr-title')\n",
    "        if h3_tag and h3_tag.a:\n",
    "            title = h3_tag.a.text.strip()\n",
    "            link = h3_tag.a['href'].strip()\n",
    "            job_data.append({\n",
    "                \"title\": title,\n",
    "                \"link\": link,\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Anchor tag not found for job: {job}\")\n",
    "\n",
    "    return job_data\n",
    "\n",
    "# Test the scraper\n",
    "url = \"https://............\"\n",
    "jobs = scrape_company_jobs(url)\n",
    "\n",
    "if jobs:\n",
    "    for job in jobs:\n",
    "        print(job)\n",
    "else:\n",
    "    print(\"No jobs found.\")\n",
    "\n",
    "# Quit the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL of the API endpoint\n",
    "api_url = \"https://.......js\" #ADD URL to API endpoint\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(api_url)\n",
    "\n",
    "# Parse the JSON response\n",
    "try:\n",
    "    job_data = response.json()  # Parse the JSON data\n",
    "    offers = job_data.get(\"offers\", [])  # Extract the 'offers' list\n",
    "\n",
    "    # Iterate through each job offer and extract relevant details\n",
    "    for offer in offers:\n",
    "        title = offer.get(\"sharing_title\", \"No Title\")\n",
    "        link = offer.get(\"careers_url\", \"No Link\")\n",
    "        location = offer.get(\"locations\", [])\n",
    "        # Just extracting the first location if multiple locations are present\n",
    "        if location:\n",
    "            location_name = location[0].get(\"name\", \"No Location\")\n",
    "        else:\n",
    "            location_name = \"No Location\"\n",
    "        \n",
    "        # Print the extracted job information\n",
    "        print(f\"Job Title: {title}\")\n",
    "        print(f\"Job Link: {link}\")\n",
    "        print(f\"Location: {location_name}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "except ValueError as e:\n",
    "    print(\"Failed to parse JSON:\", e)\n",
    "    print(\"Response content:\", response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
